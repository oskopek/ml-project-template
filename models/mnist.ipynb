{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST example notebook\n",
    "\n",
    "This is an example of how a notebook for an ML task should be structured when using TF Eager Execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = %pwd\n",
    "print('Current directory:', wd)\n",
    "if wd.endswith('models'):\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import sys, os, time, datetime\n",
    "\n",
    "try:\n",
    "    tfe.enable_eager_execution()\n",
    "except ValueError:\n",
    "    print('Eager exec already enabled.')\n",
    "\n",
    "from models.base import BaseModel\n",
    "from resources.flags import FLAGS, define_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can only be run once.\n",
    "define_flags()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the input data\n",
    "\n",
    "In this case, MNIST + batch and shuffle it. In our case, it will be quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"Returns training and test tf.data.Dataset objects.\"\"\"\n",
    "    data = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((data.train.images,\n",
    "                                                   data.train.labels))\n",
    "    test_ds = tf.data.Dataset.from_tensors(\n",
    "        (data.test.images, data.test.labels))\n",
    "    return (train_ds, test_ds)\n",
    "\n",
    "device, data_format = ('/gpu:0', 'channels_first')\n",
    "if FLAGS.no_gpu or tfe.num_gpus() <= 0:\n",
    "    device, data_format = ('/cpu:0', 'channels_last')\n",
    "print('Using device %s, and data format %s.' % (device, data_format))\n",
    "\n",
    "# Load the datasets\n",
    "train_ds, test_ds = load_data(FLAGS.in_data_dir)\n",
    "train_ds = train_ds.shuffle(60000).batch(FLAGS.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(BaseModel):\n",
    "    \"\"\"MNIST model.\n",
    "    Network structure is equivalent to:\n",
    "    https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/mnist/mnist_deep.py\n",
    "    and\n",
    "    https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py\n",
    "\n",
    "    But written using the tf.layers API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_format, name=''):\n",
    "        \"\"\"Creates a model for classifying a hand-written digit.\n",
    "\n",
    "        Args:\n",
    "          data_format: Either 'channels_first' or 'channels_last'.\n",
    "            'channels_first' is typically faster on GPUs while 'channels_last' is\n",
    "            typically faster on CPUs. See\n",
    "            https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "        \"\"\"\n",
    "        super(MNISTModel, self).__init__(name=name)\n",
    "        if data_format == 'channels_first':\n",
    "            self._input_shape = [-1, 1, 28, 28]\n",
    "        else:\n",
    "            assert data_format == 'channels_last'\n",
    "            self._input_shape = [-1, 28, 28, 1]\n",
    "        self.conv1 = self.track_layer(tf.layers.Conv2D(\n",
    "                FLAGS.conv_size,\n",
    "                5,\n",
    "                data_format=data_format,\n",
    "                activation=tf.nn.relu))\n",
    "        self.conv2 = self.track_layer(tf.layers.Conv2D(\n",
    "                FLAGS.conv_size * 2,\n",
    "                5,\n",
    "                data_format=data_format,\n",
    "                activation=tf.nn.relu))\n",
    "        self.fc1 = self.track_layer(tf.layers.Dense(1024, activation=tf.nn.relu))\n",
    "        self.fc2 = self.track_layer(tf.layers.Dense(10))\n",
    "        self.dropout = self.track_layer(tf.layers.Dropout(0.5))\n",
    "        self.max_pool2d = self.track_layer(tf.layers.MaxPooling2D(\n",
    "                (2, 2), (2, 2), padding='SAME', data_format=data_format))\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        \"\"\"Computes labels from inputs.\n",
    "\n",
    "        Users should invoke __call__ to run the network, which delegates to this\n",
    "        method (and not call this method directly).\n",
    "\n",
    "        Args:\n",
    "          inputs: A batch of images as a Tensor with shape [batch_size, 784].\n",
    "          training: True if invoked in the context of training (causing dropout to\n",
    "            be applied).  False otherwise.\n",
    "\n",
    "        Returns:\n",
    "          A Tensor with shape [batch_size, 10] containing the predicted logits\n",
    "          for each image in the batch, for each of the 10 classes.\n",
    "        \"\"\"\n",
    "\n",
    "        x = tf.reshape(inputs, self._input_shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique experiment name for each run:\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "expname = 'MNIST_conv_demo-{}-conv32_64_fc1024_10'.format(timestamp)\n",
    "\n",
    "# Create the model and optimizer\n",
    "model = MNISTModel(data_format)\n",
    "optimizer = tf.train.MomentumOptimizer(FLAGS.learning_rate, FLAGS.momentum)\n",
    "\n",
    "if FLAGS.out_data_dir:\n",
    "    train_dir = os.path.join(FLAGS.out_data_dir, expname)\n",
    "    test_dir = os.path.join(FLAGS.out_data_dir, expname, 'eval')\n",
    "    tf.gfile.MakeDirs(FLAGS.out_data_dir)\n",
    "else:\n",
    "    train_dir = None\n",
    "    test_dir = None\n",
    "\n",
    "summary_writer = tf.contrib.summary.create_file_writer(\n",
    "    train_dir, flush_millis=10000, name='train')\n",
    "test_summary_writer = tf.contrib.summary.create_file_writer(\n",
    "    test_dir, flush_millis=10000, name='test')\n",
    "checkpoint_prefix = os.path.join(FLAGS.checkpoint_dir, 'ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device):\n",
    "    for epoch in range(0, FLAGS.epochs):\n",
    "        with tfe.restore_variables_on_create(\n",
    "                tf.train.latest_checkpoint(FLAGS.checkpoint_dir)):\n",
    "            global_step = tf.train.get_or_create_global_step()\n",
    "            start = time.time()\n",
    "            with summary_writer.as_default():\n",
    "                model.train_one_epoch(optimizer, train_ds, FLAGS.log_interval)\n",
    "            end = time.time()\n",
    "            print('\\nTrain time for epoch #%d (global step %d): %f' % (\n",
    "                epoch, global_step.numpy(), end - start))\n",
    "        with test_summary_writer.as_default():\n",
    "            model.test(test_ds)\n",
    "        all_variables = (\n",
    "            model.variables +\n",
    "            optimizer.variables() +\n",
    "            [global_step])\n",
    "        tfe.Saver(all_variables).save(\n",
    "            checkpoint_prefix, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
