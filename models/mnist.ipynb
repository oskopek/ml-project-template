{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST example notebook\n",
    "\n",
    "This is an example of how a notebook for an ML task should be structured when using TF Eager Execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "from base import BaseModel\n",
    "from resources.globals import IN_DATA_DIR, OUT_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and execution parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = None\n",
    "\n",
    "FLAGS.data_dir = OUT_DATA_DIR\n",
    "\n",
    "\n",
    "PARAMS = None\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data-dir',\n",
    "    type=str,\n",
    "    default='input_data',\n",
    "    help='Directory for storing input data')\n",
    "parser.add_argument(\n",
    "    '--batch-size',\n",
    "    type=int,\n",
    "    default=64,\n",
    "    metavar='N',\n",
    "    help='input batch size for training (default: 64)')\n",
    "parser.add_argument(\n",
    "    '--log-interval',\n",
    "    type=int,\n",
    "    default=10,\n",
    "    metavar='N',\n",
    "    help='how many batches to wait before logging training status')\n",
    "parser.add_argument(\n",
    "    '--output_dir',\n",
    "    type=str,\n",
    "    default=None,\n",
    "    metavar='N',\n",
    "    help='Directory to write TensorBoard summaries')\n",
    "parser.add_argument(\n",
    "    '--checkpoint_dir',\n",
    "    type=str,\n",
    "    default='/tmp/tensorflow/mnist/checkpoints/',\n",
    "    metavar='N',\n",
    "    help='Directory to save checkpoints in (once per epoch)')\n",
    "parser.add_argument(\n",
    "    '--lr',\n",
    "    type=float,\n",
    "    default=0.01,\n",
    "    metavar='LR',\n",
    "    help='learning rate (default: 0.01)')\n",
    "parser.add_argument(\n",
    "    '--momentum',\n",
    "    type=float,\n",
    "    default=0.5,\n",
    "    metavar='M',\n",
    "    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument(\n",
    "    '--no-gpu',\n",
    "    action='store_true',\n",
    "    default=False,\n",
    "    help='disables GPU usage even if a GPU is available')\n",
    "\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the input data\n",
    "\n",
    "In this case, MNIST + batch and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\"Returns training and test tf.data.Dataset objects.\"\"\"\n",
    "    data = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((data.train.images,\n",
    "                                                   data.train.labels))\n",
    "    test_ds = tf.data.Dataset.from_tensors(\n",
    "        (data.test.images, data.test.labels))\n",
    "    return (train_ds, test_ds)\n",
    "\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "(device, data_format) = ('/gpu:0', 'channels_first')\n",
    "if FLAGS.no_gpu or tfe.num_gpus() <= 0:\n",
    "    (device, data_format) = ('/cpu:0', 'channels_last')\n",
    "print('Using device %s, and data format %s.' % (device, data_format))\n",
    "\n",
    "# Load the datasets\n",
    "train_ds, test_ds = load_data(FLAGS.data_dir)\n",
    "train_ds = train_ds.shuffle(60000).batch(FLAGS.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNISTModel(BaseModel):\n",
    "    \"\"\"MNIST model.\n",
    "    Network structure is equivalent to:\n",
    "    https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/mnist/mnist_deep.py\n",
    "    and\n",
    "    https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py\n",
    "\n",
    "    But written using the tf.layers API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_format):\n",
    "        \"\"\"Creates a model for classifying a hand-written digit.\n",
    "\n",
    "        Args:\n",
    "          data_format: Either 'channels_first' or 'channels_last'.\n",
    "            'channels_first' is typically faster on GPUs while 'channels_last' is\n",
    "            typically faster on CPUs. See\n",
    "            https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "        \"\"\"\n",
    "        super(MNISTModel, self).__init__(name='')\n",
    "        if data_format == 'channels_first':\n",
    "            self._input_shape = [-1, 1, 28, 28]\n",
    "        else:\n",
    "            assert data_format == 'channels_last'\n",
    "            self._input_shape = [-1, 28, 28, 1]\n",
    "        self.conv1 = self.track_layer(\n",
    "            tf.layers.Conv2D(\n",
    "                32,\n",
    "                5,\n",
    "                data_format=data_format,\n",
    "                activation=tf.nn.relu))\n",
    "        self.conv2 = self.track_layer(\n",
    "            tf.layers.Conv2D(\n",
    "                64,\n",
    "                5,\n",
    "                data_format=data_format,\n",
    "                activation=tf.nn.relu))\n",
    "        self.fc1 = self.track_layer(\n",
    "            tf.layers.Dense(1024, activation=tf.nn.relu))\n",
    "        self.fc2 = self.track_layer(tf.layers.Dense(10))\n",
    "        self.dropout = self.track_layer(tf.layers.Dropout(0.5))\n",
    "        self.max_pool2d = self.track_layer(\n",
    "            tf.layers.MaxPooling2D(\n",
    "                (2, 2), (2, 2), padding='SAME', data_format=data_format))\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        \"\"\"Computes labels from inputs.\n",
    "\n",
    "        Users should invoke __call__ to run the network, which delegates to this\n",
    "        method (and not call this method directly).\n",
    "\n",
    "        Args:\n",
    "          inputs: A batch of images as a Tensor with shape [batch_size, 784].\n",
    "          training: True if invoked in the context of training (causing dropout to\n",
    "            be applied).  False otherwise.\n",
    "\n",
    "        Returns:\n",
    "          A Tensor with shape [batch_size, 10] containing the predicted logits\n",
    "          for each image in the batch, for each of the 10 classes.\n",
    "        \"\"\"\n",
    "\n",
    "        x = tf.reshape(inputs, self._input_shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and optimizer\n",
    "model = MNISTModel(data_format)\n",
    "optimizer = tf.train.MomentumOptimizer(FLAGS.lr, FLAGS.momentum)\n",
    "\n",
    "if FLAGS.output_dir:\n",
    "    train_dir = os.path.join(FLAGS.output_dir, 'train')\n",
    "    test_dir = os.path.join(FLAGS.output_dir, 'eval')\n",
    "    tf.gfile.MakeDirs(FLAGS.output_dir)\n",
    "else:\n",
    "    train_dir = None\n",
    "    test_dir = None\n",
    "summary_writer = tf.contrib.summary.create_file_writer(\n",
    "    train_dir, flush_millis=10000)\n",
    "test_summary_writer = tf.contrib.summary.create_file_writer(\n",
    "    test_dir, flush_millis=10000, name='test')\n",
    "checkpoint_prefix = os.path.join(FLAGS.checkpoint_dir, 'ckpt')\n",
    "\n",
    "with tf.device(device):\n",
    "    for epoch in range(0, FLAGS.epochs):\n",
    "        with tfe.restore_variables_on_create(\n",
    "                tf.train.latest_checkpoint(FLAGS.checkpoint_dir)):\n",
    "            global_step = tf.train.get_or_create_global_step()\n",
    "            start = time.time()\n",
    "            with summary_writer.as_default():\n",
    "                train_one_epoch(model, optimizer, train_ds,\n",
    "                                FLAGS.log_interval)\n",
    "            end = time.time()\n",
    "            print('\\nTrain time for epoch #%d (global step %d): %f' % (\n",
    "                epoch, global_step.numpy(), end - start))\n",
    "        with test_summary_writer.as_default():\n",
    "            test(model, test_ds)\n",
    "        all_variables = (\n",
    "            model.variables +\n",
    "            optimizer.variables() +\n",
    "            [global_step])\n",
    "        tfe.Saver(all_variables).save(\n",
    "            checkpoint_prefix, global_step=global_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
